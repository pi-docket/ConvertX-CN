#!/bin/bash
# ==============================================================================
# ä¸‹è¼‰ MinerU VLM GGUF æ¨¡å‹
# ==============================================================================
#
# ğŸ“¦ æ¨¡å‹èªªæ˜ï¼š
#   - ä¾†æºï¼šmradermacher/MinerU2.5-2509-1.2B-GGUF
#   - é‡åŒ–ï¼šQ6_Kï¼ˆä¸»æ¨¡å‹, ~482MBï¼‰+ Q8_0ï¼ˆè¦–è¦ºæŠ•å½±å™¨, ~677MBï¼‰
#   - ç¸½å¤§å°ï¼šç´„ 1.16 GB
#   - æ¶æ§‹ï¼šqwen2vlï¼ˆVision-Language Modelï¼‰
#
# ğŸ”§ ç”¨æ–¼ï¼š
#   - Docker build éšæ®µè‡ªå‹•ä¸‹è¼‰
#   - æœ¬åœ°é–‹ç™¼æ‰‹å‹•åŸ·è¡Œ
#
# ==============================================================================

set -e

ARCH=$(uname -m)

# Docker build æˆ–æœ¬åœ°é–‹ç™¼ä½¿ç”¨ä¸åŒè·¯å¾‘
if [ -d "/opt/convertx" ]; then
    # Docker ç’°å¢ƒ
    MODEL_DIR="/opt/convertx/models/vlm/mineru2.5-2509-1.2b"
else
    # æœ¬åœ°é–‹ç™¼ç’°å¢ƒ
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
    MODEL_DIR="$PROJECT_ROOT/models/vlm/mineru2.5-2509-1.2b"
fi

# ARM64 ä¸æ”¯æ´
if [ "$ARCH" = "aarch64" ]; then
    echo "âš ï¸ ARM64ï¼šè·³é VLM GGUF æ¨¡å‹ä¸‹è¼‰"
    exit 0
fi

# æ¨¡å‹è³‡è¨Š
HF_REPO="mradermacher/MinerU2.5-2509-1.2B-GGUF"
MAIN_MODEL="MinerU2.5-2509-1.2B.Q6_K.gguf"
MMPROJ_MODEL="MinerU2.5-2509-1.2B.mmproj-Q8_0.gguf"

echo "ğŸ“¦ MinerU VLM GGUF æ¨¡å‹ä¸‹è¼‰å™¨"
echo "================================"
echo "ğŸ“ ç›®æ¨™ç›®éŒ„ï¼š$MODEL_DIR"
echo ""

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
mkdir -p "$MODEL_DIR"

# ä½¿ç”¨ Python huggingface_hub ä¸‹è¼‰ï¼ˆDocker ç’°å¢ƒå·²æœ‰ï¼‰
python3 <<PYTHON
from huggingface_hub import hf_hub_download
import os

model_dir = "$MODEL_DIR"
repo_id = "$HF_REPO"

# ä¸»æ¨¡å‹
main_model = "$MAIN_MODEL"
main_path = os.path.join(model_dir, main_model)

if os.path.isfile(main_path):
    print(f"âœ… ä¸»æ¨¡å‹å·²å­˜åœ¨ï¼š{main_model}")
else:
    print(f"â¬‡ï¸  ä¸‹è¼‰ä¸»æ¨¡å‹ï¼š{main_model} (~482 MB)")
    hf_hub_download(
        repo_id=repo_id,
        filename=main_model,
        local_dir=model_dir,
        local_dir_use_symlinks=False,
        resume_download=True
    )
    print(f"âœ… ä¸»æ¨¡å‹ä¸‹è¼‰å®Œæˆ")

# è¦–è¦ºæŠ•å½±å™¨
mmproj_model = "$MMPROJ_MODEL"
mmproj_path = os.path.join(model_dir, mmproj_model)

if os.path.isfile(mmproj_path):
    print(f"âœ… è¦–è¦ºæŠ•å½±å™¨å·²å­˜åœ¨ï¼š{mmproj_model}")
else:
    print(f"â¬‡ï¸  ä¸‹è¼‰è¦–è¦ºæŠ•å½±å™¨ï¼š{mmproj_model} (~677 MB)")
    hf_hub_download(
        repo_id=repo_id,
        filename=mmproj_model,
        local_dir=model_dir,
        local_dir_use_symlinks=False,
        resume_download=True
    )
    print(f"âœ… è¦–è¦ºæŠ•å½±å™¨ä¸‹è¼‰å®Œæˆ")

# é©—è­‰
print("")
print("ğŸ“‹ æ¨¡å‹é©—è­‰ï¼š")
if os.path.isfile(main_path) and os.path.isfile(mmproj_path):
    main_size = os.path.getsize(main_path) / 1024 / 1024
    mmproj_size = os.path.getsize(mmproj_path) / 1024 / 1024
    print(f"  âœ… {main_model}: {main_size:.1f} MB")
    print(f"  âœ… {mmproj_model}: {mmproj_size:.1f} MB")
    print(f"  ğŸ“Š ç¸½å¤§å°: {main_size + mmproj_size:.1f} MB")
else:
    print("  âŒ æ¨¡å‹é©—è­‰å¤±æ•—")
    exit(1)

print("")
print("âœ… VLM GGUF æ¨¡å‹ä¸‹è¼‰å®Œæˆï¼")
PYTHON

echo "================================"
echo "âœ… æ¨¡å‹ä¸‹è¼‰è…³æœ¬åŸ·è¡Œå®Œæˆ"
